{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9d1958b-b168-4114-86f0-602d5f1c1057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from xgboost) (2.2.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from xgboost) (1.15.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ce2e76-bd8e-46ce-8b6d-1693b9f553b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feature-engine in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (1.8.3)\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from feature-engine) (2.2.6)\n",
      "Requirement already satisfied: pandas>=2.2.0 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from feature-engine) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.4.0 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from feature-engine) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from feature-engine) (1.15.3)\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from feature-engine) (0.14.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=2.2.0->feature-engine) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=2.2.0->feature-engine) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=2.2.0->feature-engine) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->feature-engine) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn>=1.4.0->feature-engine) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn>=1.4.0->feature-engine) (3.6.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from statsmodels>=0.11.1->feature-engine) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from statsmodels>=0.11.1->feature-engine) (24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install feature-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b2c4837-865d-4491-9835-85c4ccaeabbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feature-engine in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (1.8.3)\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from feature-engine) (2.2.6)\n",
      "Requirement already satisfied: pandas>=2.2.0 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from feature-engine) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.4.0 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from feature-engine) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from feature-engine) (1.15.3)\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from feature-engine) (0.14.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=2.2.0->feature-engine) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=2.2.0->feature-engine) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=2.2.0->feature-engine) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->feature-engine) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn>=1.4.0->feature-engine) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn>=1.4.0->feature-engine) (3.6.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from statsmodels>=0.11.1->feature-engine) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from statsmodels>=0.11.1->feature-engine) (24.2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (\n",
    "\tOneHotEncoder,\n",
    "\tOrdinalEncoder,\n",
    "\tStandardScaler,\n",
    "\tMinMaxScaler,\n",
    "\tPowerTransformer,\n",
    "\tFunctionTransformer\n",
    ")\n",
    "!pip install feature-engine\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from feature_engine.datetime import DatetimeFeatures\n",
    "from feature_engine.selection import SelectBySingleFeaturePerformance\n",
    "from feature_engine.encoding import (\n",
    "\tRareLabelEncoder,\n",
    "\tMeanEncoder,\n",
    "\tCountFrequencyEncoder\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baadc2e0-0188-4eea-9547-78eb66826da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed42a25-d29e-4474-bee3-9f59ddb0984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.set_config(transform_output=\"pandas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6fcbf99-b7da-4bab-ae9d-1b1a78446c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd66d6-eee7-4ac9-910a-a7400457a17a",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e161a3b3-7fcc-4b0c-b811-114d5fad8ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>date_of_journey</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>total_stops</th>\n",
       "      <th>additional_info</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>20:55:00</td>\n",
       "      <td>12:35:00</td>\n",
       "      <td>940</td>\n",
       "      <td>1</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "      <td>12898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>18:55:00</td>\n",
       "      <td>16:20:00</td>\n",
       "      <td>1285</td>\n",
       "      <td>1</td>\n",
       "      <td>No Info</td>\n",
       "      <td>13044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Air India</td>\n",
       "      <td>2019-05-18</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>09:45:00</td>\n",
       "      <td>09:25:00</td>\n",
       "      <td>1420</td>\n",
       "      <td>2</td>\n",
       "      <td>No Info</td>\n",
       "      <td>10975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indigo</td>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>21:20:00</td>\n",
       "      <td>22:50:00</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>2227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>02:55:00</td>\n",
       "      <td>04:20:00</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>5678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6689</th>\n",
       "      <td>Spicejet</td>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>11:35:00</td>\n",
       "      <td>18:50:00</td>\n",
       "      <td>435</td>\n",
       "      <td>1</td>\n",
       "      <td>No Info</td>\n",
       "      <td>8479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6690</th>\n",
       "      <td>Multiple Carriers</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>01:30:00</td>\n",
       "      <td>930</td>\n",
       "      <td>1</td>\n",
       "      <td>No Info</td>\n",
       "      <td>15078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6691</th>\n",
       "      <td>Air India</td>\n",
       "      <td>2019-05-18</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>07:40:00</td>\n",
       "      <td>1180</td>\n",
       "      <td>2</td>\n",
       "      <td>No Info</td>\n",
       "      <td>8603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6692</th>\n",
       "      <td>Air Asia</td>\n",
       "      <td>2019-05-18</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>07:55:00</td>\n",
       "      <td>13:25:00</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>No Info</td>\n",
       "      <td>8759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6693</th>\n",
       "      <td>Multiple Carriers</td>\n",
       "      <td>2019-04-09</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>660</td>\n",
       "      <td>1</td>\n",
       "      <td>No Info</td>\n",
       "      <td>11142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6694 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                airline date_of_journey   source destination  dep_time  \\\n",
       "0           Jet Airways      2019-05-27    Delhi      Cochin  20:55:00   \n",
       "1           Jet Airways      2019-06-12  Kolkata    Banglore  18:55:00   \n",
       "2             Air India      2019-05-18    Delhi      Cochin  09:45:00   \n",
       "3                Indigo      2019-06-03   Mumbai   Hyderabad  21:20:00   \n",
       "4           Jet Airways      2019-04-01   Mumbai   Hyderabad  02:55:00   \n",
       "...                 ...             ...      ...         ...       ...   \n",
       "6689           Spicejet      2019-06-09  Kolkata    Banglore  11:35:00   \n",
       "6690  Multiple Carriers      2019-05-09    Delhi      Cochin  10:00:00   \n",
       "6691          Air India      2019-05-18    Delhi      Cochin  12:00:00   \n",
       "6692           Air Asia      2019-05-18    Delhi      Cochin  07:55:00   \n",
       "6693  Multiple Carriers      2019-04-09    Delhi      Cochin  08:00:00   \n",
       "\n",
       "     arrival_time  duration  total_stops              additional_info  price  \n",
       "0        12:35:00       940            1  In-flight meal not included  12898  \n",
       "1        16:20:00      1285            1                      No Info  13044  \n",
       "2        09:25:00      1420            2                      No Info  10975  \n",
       "3        22:50:00        90            0                      No Info   2227  \n",
       "4        04:20:00        85            0                      No Info   5678  \n",
       "...           ...       ...          ...                          ...    ...  \n",
       "6689     18:50:00       435            1                      No Info   8479  \n",
       "6690     01:30:00       930            1                      No Info  15078  \n",
       "6691     07:40:00      1180            2                      No Info   8603  \n",
       "6692     13:25:00       330            1                      No Info   8759  \n",
       "6693     19:00:00       660            1                      No Info  11142  \n",
       "\n",
       "[6694 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_1 = r\"C:\\Users\\User\\Desktop\\Learnabay Training\\My Portfolio projects for resume\\Flight Price Prediction\\Data\\train.csv\"\n",
    "\n",
    "train = pd.read_csv(path_1)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad00221-6b9a-441f-a0a1-bee5cd3cbf7d",
   "metadata": {},
   "source": [
    "## Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33afd169-ed65-49a6-a789-023f29471507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>date_of_journey</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>total_stops</th>\n",
       "      <th>additional_info</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "      <td>10675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-05-24</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>18:55:00</td>\n",
       "      <td>10:05:00</td>\n",
       "      <td>910</td>\n",
       "      <td>1</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "      <td>8586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>21:25:00</td>\n",
       "      <td>09:30:00</td>\n",
       "      <td>725</td>\n",
       "      <td>1</td>\n",
       "      <td>No Info</td>\n",
       "      <td>13555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spicejet</td>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>17:45:00</td>\n",
       "      <td>20:05:00</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>No check-in baggage included</td>\n",
       "      <td>3543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Asia</td>\n",
       "      <td>2019-05-15</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>07:35:00</td>\n",
       "      <td>19:25:00</td>\n",
       "      <td>710</td>\n",
       "      <td>1</td>\n",
       "      <td>No Info</td>\n",
       "      <td>5192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>07:10:00</td>\n",
       "      <td>22:40:00</td>\n",
       "      <td>930</td>\n",
       "      <td>1</td>\n",
       "      <td>No Info</td>\n",
       "      <td>8452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>Indigo</td>\n",
       "      <td>2019-04-03</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>21:05:00</td>\n",
       "      <td>00:20:00</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>5021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>Air India</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>19:45:00</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>25913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>Air India</td>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>06:20:00</td>\n",
       "      <td>07:40:00</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>17:30:00</td>\n",
       "      <td>04:25:00</td>\n",
       "      <td>655</td>\n",
       "      <td>1</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "      <td>6540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1674 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          airline date_of_journey    source destination  dep_time  \\\n",
       "0     Jet Airways      2019-05-27     Delhi      Cochin  09:00:00   \n",
       "1     Jet Airways      2019-05-24   Kolkata    Banglore  18:55:00   \n",
       "2     Jet Airways      2019-03-18  Banglore       Delhi  21:25:00   \n",
       "3        Spicejet      2019-06-27   Chennai     Kolkata  17:45:00   \n",
       "4        Air Asia      2019-05-15   Kolkata    Banglore  07:35:00   \n",
       "...           ...             ...       ...         ...       ...   \n",
       "1669      Vistara      2019-05-06   Kolkata    Banglore  07:10:00   \n",
       "1670       Indigo      2019-04-03     Delhi      Cochin  21:05:00   \n",
       "1671    Air India      2019-03-01  Banglore       Delhi  17:00:00   \n",
       "1672    Air India      2019-06-18    Mumbai   Hyderabad  06:20:00   \n",
       "1673  Jet Airways      2019-03-27     Delhi      Cochin  17:30:00   \n",
       "\n",
       "     arrival_time  duration  total_stops               additional_info  price  \n",
       "0        19:00:00       600            1   In-flight meal not included  10675  \n",
       "1        10:05:00       910            1   In-flight meal not included   8586  \n",
       "2        09:30:00       725            1                       No Info  13555  \n",
       "3        20:05:00       140            0  No check-in baggage included   3543  \n",
       "4        19:25:00       710            1                       No Info   5192  \n",
       "...           ...       ...          ...                           ...    ...  \n",
       "1669     22:40:00       930            1                       No Info   8452  \n",
       "1670     00:20:00       195            0                       No Info   5021  \n",
       "1671     19:45:00       165            0                       No Info  25913  \n",
       "1672     07:40:00        80            0                       No Info   3100  \n",
       "1673     04:25:00       655            1   In-flight meal not included   6540  \n",
       "\n",
       "[1674 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_2 = r\"C:\\Users\\User\\Desktop\\Learnabay Training\\My Portfolio projects for resume\\Flight Price Prediction\\Data\\val.csv\"\n",
    "\n",
    "val = pd.read_csv(path_2)\n",
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c72a338-1e58-4ca7-9bd5-6b5611d94c03",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "307e4989-0387-4788-85b5-210ae864293f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>date_of_journey</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>total_stops</th>\n",
       "      <th>additional_info</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>08:15:00</td>\n",
       "      <td>1455</td>\n",
       "      <td>1</td>\n",
       "      <td>No Info</td>\n",
       "      <td>17996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spicejet</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>22:20:00</td>\n",
       "      <td>00:40:00</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>3873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indigo</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>05:30:00</td>\n",
       "      <td>08:20:00</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>4462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>15:50:00</td>\n",
       "      <td>17:20:00</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "      <td>2228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spicejet</td>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>09:30:00</td>\n",
       "      <td>12:20:00</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>4991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>19:15:00</td>\n",
       "      <td>12:35:00</td>\n",
       "      <td>1040</td>\n",
       "      <td>1</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "      <td>12898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>02:15:00</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "      <td>12898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>02:15:00</td>\n",
       "      <td>04:25:00</td>\n",
       "      <td>1570</td>\n",
       "      <td>1</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "      <td>11627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>Multiple Carriers</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>15:15:00</td>\n",
       "      <td>01:30:00</td>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>No Info</td>\n",
       "      <td>6795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>Multiple Carriers</td>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>18:15:00</td>\n",
       "      <td>01:30:00</td>\n",
       "      <td>435</td>\n",
       "      <td>1</td>\n",
       "      <td>No Info</td>\n",
       "      <td>13377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2093 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                airline date_of_journey    source destination  dep_time  \\\n",
       "0           Jet Airways      2019-03-06  Banglore       Delhi  08:00:00   \n",
       "1              Spicejet      2019-06-06   Kolkata    Banglore  22:20:00   \n",
       "2                Indigo      2019-03-18   Kolkata    Banglore  05:30:00   \n",
       "3           Jet Airways      2019-03-24    Mumbai   Hyderabad  15:50:00   \n",
       "4              Spicejet      2019-04-27  Banglore       Delhi  09:30:00   \n",
       "...                 ...             ...       ...         ...       ...   \n",
       "2088        Jet Airways      2019-05-27     Delhi      Cochin  19:15:00   \n",
       "2089        Jet Airways      2019-05-27     Delhi      Cochin  02:15:00   \n",
       "2090        Jet Airways      2019-06-03     Delhi      Cochin  02:15:00   \n",
       "2091  Multiple Carriers      2019-06-06     Delhi      Cochin  15:15:00   \n",
       "2092  Multiple Carriers      2019-06-03     Delhi      Cochin  18:15:00   \n",
       "\n",
       "     arrival_time  duration  total_stops              additional_info  price  \n",
       "0        08:15:00      1455            1                      No Info  17996  \n",
       "1        00:40:00       140            0                      No Info   3873  \n",
       "2        08:20:00       170            0                      No Info   4462  \n",
       "3        17:20:00        90            0  In-flight meal not included   2228  \n",
       "4        12:20:00       170            0                      No Info   4991  \n",
       "...           ...       ...          ...                          ...    ...  \n",
       "2088     12:35:00      1040            1  In-flight meal not included  12898  \n",
       "2089     19:00:00      1005            1  In-flight meal not included  12898  \n",
       "2090     04:25:00      1570            1  In-flight meal not included  11627  \n",
       "2091     01:30:00       615            1                      No Info   6795  \n",
       "2092     01:30:00       435            1                      No Info  13377  \n",
       "\n",
       "[2093 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_3 = r\"C:\\Users\\User\\Desktop\\Learnabay Training\\My Portfolio projects for resume\\Flight Price Prediction\\Data\\test.csv\"\n",
    "\n",
    "test = pd.read_csv(path_3)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f34c80b-3188-4aa0-ac21-948df826eac8",
   "metadata": {},
   "source": [
    "## Preprocessing Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c120a8c8-26b8-49b0-9f00-d44a153a1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Airline\n",
    "air_transformer = Pipeline(steps=[\n",
    "\t(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "\t(\"grouper\", RareLabelEncoder(tol=0.1, replace_with=\"Other\", n_categories=2)),\n",
    "\t(\"encoder\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_to_extract = [\"year\", \"month\", \"week\", \"day_of_week\",\"day_of_month\",\"weekend\", \"day_of_year\",\"month_start\",\"month_end\", \"quarter\"]\n",
    "\n",
    "doj_transformer = Pipeline(steps=[\n",
    "\t(\"dt\", DatetimeFeatures(features_to_extract=feature_to_extract, yearfirst=True, format=\"mixed\")),\n",
    "\t(\"scaler\", MinMaxScaler())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "location_pipe1 = Pipeline(steps=[\n",
    "\t(\"encoder\", MeanEncoder()),\n",
    "\t(\"scaler\", PowerTransformer())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "def is_south(X):\n",
    "\tcolumns = X.columns.to_list()\n",
    "\tsouth_cities = ['Banglore', 'Chennai', 'Cochin', 'Hyderabad']\n",
    "\treturn (\n",
    "\t\tX\n",
    "\t\t.assign(**{\n",
    "\t\t\tf\"{col}_is_south\": X.loc[:, col].isin(south_cities).astype(int)\n",
    "\t\t\tfor col in columns\n",
    "\t\t})\n",
    "\t\t.drop(columns=columns)\n",
    "\t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "location_transformer = FeatureUnion(transformer_list=[\n",
    "\t(\"part1\", location_pipe1),\n",
    "\t(\"part2\", FunctionTransformer(func=is_south))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "time_pipe1 = Pipeline(steps=[\n",
    "\t(\"dt\", DatetimeFeatures(features_to_extract=[\"hour\", \"minute\"])),\n",
    "\t(\"scaler\", MinMaxScaler())\n",
    "])\n",
    "\n",
    "\n",
    "def part_of_day(X, morning=4, noon=12, eve=16, night=20):\n",
    "\tcolumns = X.columns.to_list()\n",
    "\tX_temp = X.assign(**{\n",
    "\t\tcol: pd.to_datetime(X.loc[:, col]).dt.hour\n",
    "\t\tfor col in columns\n",
    "\t})\n",
    "\n",
    "\treturn (\n",
    "\t\tX_temp\n",
    "\t\t.assign(**{\n",
    "\t\t\tf\"{col}_part_of_day\": np.select(\n",
    "\t\t\t\t[X_temp.loc[:, col].between(morning, noon, inclusive=\"left\"),\n",
    "\t\t\t\t X_temp.loc[:, col].between(noon, eve, inclusive=\"left\"),\n",
    "\t\t\t\t X_temp.loc[:, col].between(eve, night, inclusive=\"left\")],\n",
    "\t\t\t\t[\"morning\", \"afternoon\", \"evening\"],\n",
    "\t\t\t\tdefault=\"night\"\n",
    "\t\t\t)\n",
    "\t\t\tfor col in columns\n",
    "\t\t})\n",
    "\t\t.drop(columns=columns)\n",
    "\t)\n",
    "\n",
    "time_pipe2 = Pipeline(steps=[\n",
    "\t(\"part\", FunctionTransformer(func=part_of_day)),\n",
    "\t(\"encoder\", CountFrequencyEncoder()),\n",
    "\t(\"scaler\", MinMaxScaler())\n",
    "])\n",
    "\n",
    "time_transformer = FeatureUnion(transformer_list=[\n",
    "\t(\"part1\", time_pipe1),\n",
    "\t(\"part2\", time_pipe2)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RBFPercentileSimilarity(BaseEstimator, TransformerMixin):\n",
    "\tdef __init__(self, variables=None, percentiles=[0.25, 0.5, 0.75], gamma=0.1):\n",
    "\t\tself.variables = variables\n",
    "\t\tself.percentiles = percentiles\n",
    "\t\tself.gamma = gamma\n",
    "\n",
    "\n",
    "\tdef fit(self, X, y=None):\n",
    "\t\tif not self.variables:\n",
    "\t\t\tself.variables = X.select_dtypes(include=\"number\").columns.to_list()\n",
    "\n",
    "\t\tself.reference_values_ = {\n",
    "\t\t\tcol: (\n",
    "\t\t\t\tX\n",
    "\t\t\t\t.loc[:, col]\n",
    "\t\t\t\t.quantile(self.percentiles)\n",
    "\t\t\t\t.values\n",
    "\t\t\t\t.reshape(-1, 1)\n",
    "\t\t\t)\n",
    "\t\t\tfor col in self.variables\n",
    "\t\t}\n",
    "\n",
    "\t\treturn self\n",
    "\n",
    "\n",
    "\tdef transform(self, X):\n",
    "\t\tobjects = []\n",
    "\t\tfor col in self.variables:\n",
    "\t\t\tcolumns = [f\"{col}_rbf_{int(percentile * 100)}\" for percentile in self.percentiles]\n",
    "\t\t\tobj = pd.DataFrame(\n",
    "\t\t\t\tdata=rbf_kernel(X.loc[:, [col]], Y=self.reference_values_[col], gamma=self.gamma),\n",
    "\t\t\t\tcolumns=columns\n",
    "\t\t\t)\n",
    "\t\t\tobjects.append(obj)\n",
    "\t\treturn pd.concat(objects, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def duration_category(X, short=180, med=400):\n",
    "\treturn (\n",
    "\t\tX\n",
    "\t\t.assign(duration_cat=np.select([X.duration.lt(short),\n",
    "\t\t\t\t\t\t\t\t\t    X.duration.between(short, med, inclusive=\"left\")],\n",
    "\t\t\t\t\t\t\t\t\t   [\"short\", \"medium\"],\n",
    "\t\t\t\t\t\t\t\t\t   default=\"long\"))\n",
    "\t\t.drop(columns=\"duration\")\n",
    "\t)\n",
    "\n",
    "\n",
    "\n",
    "def is_over(X, value=1000):\n",
    "\treturn (\n",
    "\t\tX\n",
    "\t\t.assign(**{\n",
    "\t\t\tf\"duration_over_{value}\": X.duration.ge(value).astype(int)\n",
    "\t\t})\n",
    "\t\t.drop(columns=\"duration\")\n",
    "\t)\n",
    "\n",
    "duration_pipe1 = Pipeline(steps=[\n",
    "\t(\"rbf\", RBFPercentileSimilarity()),\n",
    "\t(\"scaler\", PowerTransformer())\n",
    "])\n",
    "\n",
    "duration_pipe2 = Pipeline(steps=[\n",
    "\t(\"cat\", FunctionTransformer(func=duration_category)),\n",
    "\t(\"encoder\", OrdinalEncoder(categories=[[\"short\", \"medium\", \"long\"]]))\n",
    "])\n",
    "\n",
    "duration_union = FeatureUnion(transformer_list=[\n",
    "\t(\"part1\", duration_pipe1),\n",
    "\t(\"part2\", duration_pipe2),\n",
    "\t(\"part3\", FunctionTransformer(func=is_over)),\n",
    "\t(\"part4\", StandardScaler())\n",
    "])\n",
    "\n",
    "duration_transformer = Pipeline(steps=[\n",
    "\t(\"outliers\", Winsorizer(capping_method=\"iqr\", fold=1.5)),\n",
    "\t(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "\t(\"union\", duration_union)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def is_direct(X):\n",
    "\treturn X.assign(is_direct_flight=X.total_stops.eq(0).astype(int))\n",
    "\n",
    "\n",
    "total_stops_transformer = Pipeline(steps=[\n",
    "\t(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "\t(\"\", FunctionTransformer(func=is_direct))\n",
    "])\n",
    "\n",
    "\n",
    "info_pipe1 = Pipeline(steps=[\n",
    "\t(\"group\", RareLabelEncoder(tol=0.1, n_categories=2, replace_with=\"Other\")),\n",
    "\t(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "def have_info(X):\n",
    "\treturn X.assign(additional_info=X.additional_info.ne(\"No Info\").astype(int))\n",
    "\n",
    "info_union = FeatureUnion(transformer_list=[\n",
    "\t(\"part1\", info_pipe1),\n",
    "\t(\"part2\", FunctionTransformer(func=have_info))\n",
    "])\n",
    "\n",
    "info_transformer = Pipeline(steps=[\n",
    "\t(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")),\n",
    "\t(\"union\", info_union)\n",
    "])\n",
    "\n",
    "column_transformer = ColumnTransformer(transformers=[\n",
    "\t(\"air\", air_transformer, [\"airline\"]),\n",
    "\t(\"doj\", doj_transformer, [\"date_of_journey\"]),\n",
    "\t(\"location\", location_transformer, [\"source\", 'destination']),\n",
    "\t(\"time\", time_transformer, [\"dep_time\", \"arrival_time\"]),\n",
    "\t(\"dur\", duration_transformer, [\"duration\"]),\n",
    "\t(\"stops\", total_stops_transformer, [\"total_stops\"]),\n",
    "\t(\"info\", info_transformer, [\"additional_info\"])\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "\n",
    "estimator = RandomForestRegressor(n_estimators=10, max_depth=3, random_state=42)\n",
    "\n",
    "selector = SelectBySingleFeaturePerformance(\n",
    "\testimator=estimator,\n",
    "\tscoring=\"r2\",\n",
    "\tthreshold=0.1\n",
    ") \n",
    "\n",
    "\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "\t(\"ct\", column_transformer),\n",
    "\t(\"selector\", selector)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197c43e9-4015-443e-b500-0b555d075093",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5feac35e-045d-4210-b335-8e9768ab6cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (6694, 9) (6694,)\n",
      "Validation: (1674, 9) (1674,)\n",
      "Test: (2093, 9) (2093,)\n"
     ]
    }
   ],
   "source": [
    "# Split into features and target\n",
    "X_train = train.drop(columns=[\"price\"])\n",
    "y_train = train[\"price\"]\n",
    "\n",
    "X_val = val.drop(columns=[\"price\"])\n",
    "y_val = val[\"price\"]\n",
    "\n",
    "X_test = test.drop(columns=[\"price\"])\n",
    "y_test = test[\"price\"]\n",
    "\n",
    "# Optional: print shapes to confirm\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation:\", X_val.shape, y_val.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8257831-f33e-40ac-be92-cf778da37abf",
   "metadata": {},
   "source": [
    "## Base-Level Prediction on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0c1989d-d2ef-45ec-8571-3f690edb4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import clone\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f266af6-f28c-4091-b52e-eb9faf07c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your preprocessor for reuse\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", clone(preprocessor)),\n",
    "    (\"regressor\", RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", clone(preprocessor)),\n",
    "    (\"regressor\", XGBRegressor(random_state=42, verbosity=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9b9187d-ad4b-4001-af82-257f9e856475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_model(pipeline, X, y, model_name=\"Model\"):\n",
    "    y_pred = pipeline.predict(X)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    adj_r2 = 1 - (1 - r2) * ((len(y) - 1) / (len(y) - X.shape[1] - 1))\n",
    "    \n",
    "    print(f\"\\n{model_name} Results on Training Set:\")\n",
    "    print(f\"  MSE     : {mse:.4f}\")\n",
    "    print(f\"  R2      : {r2:.4f}\")\n",
    "    print(f\"  Adj R2  : {adj_r2:.4f}\")\n",
    "    \n",
    "    return {\"model\": model_name, \"mse\": mse, \"r2\": r2, \"adj_r2\": adj_r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "491f679d-a647-453b-b738-0d0142d0771c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Results on Training Set:\n",
      "  MSE     : 1647554.8064\n",
      "  R2      : 0.9245\n",
      "  Adj R2  : 0.9244\n",
      "\n",
      "XGBoost Results on Training Set:\n",
      "  MSE     : 2162472.0000\n",
      "  R2      : 0.9009\n",
      "  Adj R2  : 0.9007\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Random Forest\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "rf_results = evaluate_model(rf_pipeline, X_train, y_train, \"Random Forest\")\n",
    "\n",
    "# Train and evaluate XGBoost\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "xgb_results = evaluate_model(xgb_pipeline, X_train, y_train, \"XGBoost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcca00cd-2948-479e-8009-e05824a9f392",
   "metadata": {},
   "source": [
    "## Optuna tuning on Train + val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed54a4dd-7fce-4274-bff8-03bddbb6b4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined training data shape: (8368, 13) (8368,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Clone and fit preprocessor on train\n",
    "fitted_preprocessor = clone(preprocessor)\n",
    "fitted_preprocessor.fit(X_train,y_train)\n",
    "\n",
    "# Transform train and val\n",
    "X_train_trans = fitted_preprocessor.transform(X_train)\n",
    "X_val_trans = fitted_preprocessor.transform(X_val)\n",
    "\n",
    "# Combine train and val sets\n",
    "X_full_train = pd.DataFrame(\n",
    "    data=np.vstack([X_train_trans, X_val_trans])\n",
    ")\n",
    "y_full_train = pd.concat([y_train, y_val]).reset_index(drop=True)\n",
    "\n",
    "print(\"✅ Combined training data shape:\", X_full_train.shape, y_full_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06b88b5e-ccb9-41ef-a990-f4af08d0ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [ \"sqrt\", \"log2\"]),\n",
    "        \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    model = RandomForestRegressor(**params)\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    mse_scores = cross_val_score(model, X_full_train, y_full_train,\n",
    "                                 cv=kf,\n",
    "                                 scoring=make_scorer(mean_squared_error, greater_is_better=False))\n",
    "    \n",
    "    return -np.mean(mse_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f6e7896-cc9c-44ab-90a0-8f96d7f67f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 22:07:45,286] A new study created in memory with name: no-name-48027cb9-9ff0-4ac5-9fb4-3c06a6f3d64e\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e62dd7947824000aea51813e3b6e95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-05-30 22:07:48,314] Trial 0 finished with value: 5471311.893504297 and parameters: {'n_estimators': 296, 'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 5471311.893504297.\n",
      "[I 2025-05-30 22:07:50,178] Trial 1 finished with value: 5514177.181631086 and parameters: {'n_estimators': 154, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 5471311.893504297.\n",
      "[I 2025-05-30 22:07:52,195] Trial 2 finished with value: 5665765.903161746 and parameters: {'n_estimators': 199, 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 5471311.893504297.\n",
      "[I 2025-05-30 22:07:54,595] Trial 3 finished with value: 6959037.852924156 and parameters: {'n_estimators': 283, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 5471311.893504297.\n",
      "[I 2025-05-30 22:07:55,695] Trial 4 finished with value: 8757084.778435575 and parameters: {'n_estimators': 114, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 5471311.893504297.\n",
      "[I 2025-05-30 22:07:59,033] Trial 5 finished with value: 5316026.3750264635 and parameters: {'n_estimators': 276, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 5 with value: 5316026.3750264635.\n",
      "[I 2025-05-30 22:08:02,213] Trial 6 finished with value: 5261766.935561424 and parameters: {'n_estimators': 260, 'max_depth': 17, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 6 with value: 5261766.935561424.\n",
      "[I 2025-05-30 22:08:03,480] Trial 7 finished with value: 8825843.71385232 and parameters: {'n_estimators': 128, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 6 with value: 5261766.935561424.\n",
      "[I 2025-05-30 22:08:05,812] Trial 8 finished with value: 5890419.105486017 and parameters: {'n_estimators': 218, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_features': 'log2', 'bootstrap': False}. Best is trial 6 with value: 5261766.935561424.\n",
      "[I 2025-05-30 22:08:08,777] Trial 9 finished with value: 5318756.21457907 and parameters: {'n_estimators': 248, 'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 6 with value: 5261766.935561424.\n",
      "[I 2025-05-30 22:08:11,017] Trial 10 finished with value: 5195794.690602097 and parameters: {'n_estimators': 190, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 10 with value: 5195794.690602097.\n",
      "[I 2025-05-30 22:08:13,430] Trial 11 finished with value: 5154068.472731759 and parameters: {'n_estimators': 185, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:15,659] Trial 12 finished with value: 5339738.603607891 and parameters: {'n_estimators': 188, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:17,700] Trial 13 finished with value: 5211823.548477333 and parameters: {'n_estimators': 163, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:20,681] Trial 14 finished with value: 5607102.430025594 and parameters: {'n_estimators': 216, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:22,483] Trial 15 finished with value: 5513625.311764994 and parameters: {'n_estimators': 167, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:24,965] Trial 16 finished with value: 5262893.90804236 and parameters: {'n_estimators': 232, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:26,873] Trial 17 finished with value: 5620137.515677525 and parameters: {'n_estimators': 182, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:28,612] Trial 18 finished with value: 5332726.396057214 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:29,756] Trial 19 finished with value: 6387609.787820019 and parameters: {'n_estimators': 102, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:32,502] Trial 20 finished with value: 5312188.396707045 and parameters: {'n_estimators': 213, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:34,552] Trial 21 finished with value: 5216163.490073361 and parameters: {'n_estimators': 171, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:36,564] Trial 22 finished with value: 5308429.7839001445 and parameters: {'n_estimators': 152, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:39,003] Trial 23 finished with value: 5308278.3749514725 and parameters: {'n_estimators': 192, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:41,296] Trial 24 finished with value: 5155741.448368449 and parameters: {'n_estimators': 158, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:43,384] Trial 25 finished with value: 5226927.968031095 and parameters: {'n_estimators': 141, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:45,284] Trial 26 finished with value: 5420077.078486885 and parameters: {'n_estimators': 179, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:47,824] Trial 27 finished with value: 5262834.833614822 and parameters: {'n_estimators': 209, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:49,947] Trial 28 finished with value: 6349949.939021099 and parameters: {'n_estimators': 236, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:51,758] Trial 29 finished with value: 5317525.058878844 and parameters: {'n_estimators': 125, 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:53,870] Trial 30 finished with value: 5322289.955467658 and parameters: {'n_estimators': 151, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:55,723] Trial 31 finished with value: 5228491.86144584 and parameters: {'n_estimators': 164, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:08:57,804] Trial 32 finished with value: 5212708.146286234 and parameters: {'n_estimators': 175, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:00,408] Trial 33 finished with value: 5257623.005913047 and parameters: {'n_estimators': 199, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:02,289] Trial 34 finished with value: 5255635.814755392 and parameters: {'n_estimators': 160, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:04,040] Trial 35 finished with value: 5621234.429067677 and parameters: {'n_estimators': 140, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:06,691] Trial 36 finished with value: 5444876.80277743 and parameters: {'n_estimators': 193, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:09,087] Trial 37 finished with value: 5231668.528754972 and parameters: {'n_estimators': 205, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:12,597] Trial 38 finished with value: 5296859.891612098 and parameters: {'n_estimators': 300, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:14,716] Trial 39 finished with value: 5207515.557903508 and parameters: {'n_estimators': 154, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:16,599] Trial 40 finished with value: 5316646.891944142 and parameters: {'n_estimators': 126, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:18,833] Trial 41 finished with value: 5207997.2538861865 and parameters: {'n_estimators': 157, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:20,955] Trial 42 finished with value: 5204928.683941714 and parameters: {'n_estimators': 149, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:23,035] Trial 43 finished with value: 5320803.425106126 and parameters: {'n_estimators': 146, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:25,264] Trial 44 finished with value: 5226455.856952026 and parameters: {'n_estimators': 184, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:26,712] Trial 45 finished with value: 5203728.210441722 and parameters: {'n_estimators': 110, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:27,940] Trial 46 finished with value: 5387165.660480924 and parameters: {'n_estimators': 101, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:29,570] Trial 47 finished with value: 5515753.823317951 and parameters: {'n_estimators': 130, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 'log2', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:30,839] Trial 48 finished with value: 5766964.761939331 and parameters: {'n_estimators': 111, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False}. Best is trial 11 with value: 5154068.472731759.\n",
      "[I 2025-05-30 22:09:32,934] Trial 49 finished with value: 5409288.30631279 and parameters: {'n_estimators': 228, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 11 with value: 5154068.472731759.\n",
      "\n",
      "🔍 Best Trial:\n",
      "  MSE     : 5154068.472731759\n",
      "  Params  : {'n_estimators': 185, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n🔍 Best Trial:\")\n",
    "print(f\"  MSE     : {study.best_value}\")\n",
    "print(f\"  Params  : {study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9c1bad-68fe-49f2-8830-baa50cac2216",
   "metadata": {},
   "source": [
    "## Training and Prediction with best parameters on Train+val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01b6ac42-ffd8-49bd-81eb-ebbdae8b803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Training + Validation Set Metrics:\n",
      "  MSE     : 3,681,142.24\n",
      "  RMSE    : 1,918.63\n",
      "  MAE     : 1,234.70\n",
      "  R²      : 0.8292\n",
      "  Adj R²  : 0.8289\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Best parameters\n",
    "best_params = {\n",
    "    'n_estimators': 242,\n",
    "    'max_depth': 13,\n",
    "    'min_samples_split': 9,\n",
    "    'min_samples_leaf': 1,\n",
    "    'max_features': 'sqrt',\n",
    "    'bootstrap': True,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Train model on preprocessed train+val data\n",
    "model = RandomForestRegressor(**best_params)\n",
    "model.fit(X_full_train, y_full_train)\n",
    "\n",
    "# Predict on train+val\n",
    "y_trainval_pred = model.predict(X_full_train)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_full_train, y_trainval_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_full_train, y_trainval_pred)\n",
    "r2 = r2_score(y_full_train, y_trainval_pred)\n",
    "\n",
    "# Adjusted R²\n",
    "n = X_full_train.shape[0]\n",
    "p = X_full_train.shape[1]\n",
    "adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "# Output\n",
    "print(\"🔍 Training + Validation Set Metrics:\")\n",
    "print(f\"  MSE     : {mse:,.2f}\")\n",
    "print(f\"  RMSE    : {rmse:,.2f}\")\n",
    "print(f\"  MAE     : {mae:,.2f}\")\n",
    "print(f\"  R²      : {r2:.4f}\")\n",
    "print(f\"  Adj R²  : {adj_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaec545-2f8a-4906-8165-b3cca91424f3",
   "metadata": {},
   "source": [
    "## Prediction and Final Results on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4d1c461-18a5-457c-a794-34d4952218d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Test Set Evaluation Metrics (after transformation):\n",
      "  MSE     : 4,278,251.73\n",
      "  RMSE    : 2,068.39\n",
      "  MAE     : 1,406.11\n",
      "  R²      : 0.7932\n",
      "  Adj R²  : 0.7919\n",
      "  MAPE    : 16.61%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Transform X_test\n",
    "X_test_transformed = fitted_preprocessor.transform(X_test)\n",
    "\n",
    "# Step 2: Predict using trained model\n",
    "y_test_pred = model.predict(X_test_transformed)\n",
    "\n",
    "# Step 3: Evaluate\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Adjusted R²\n",
    "n_test = X_test_transformed.shape[0]\n",
    "p_test = X_test_transformed.shape[1]\n",
    "adj_r2_test = 1 - (1 - r2_test) * (n_test - 1) / (n_test - p_test - 1)\n",
    "\n",
    "# Optional: MAPE\n",
    "mape_test = np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100 if np.all(y_test != 0) else None\n",
    "\n",
    "# Step 4: Print\n",
    "print(\"\\n🔍 Test Set Evaluation Metrics (after transformation):\")\n",
    "print(f\"  MSE     : {mse_test:,.2f}\")\n",
    "print(f\"  RMSE    : {rmse_test:,.2f}\")\n",
    "print(f\"  MAE     : {mae_test:,.2f}\")\n",
    "print(f\"  R²      : {r2_test:.4f}\")\n",
    "print(f\"  Adj R²  : {adj_r2_test:.4f}\")\n",
    "if mape_test is not None:\n",
    "    print(f\"  MAPE    : {mape_test:.2f}%\")\n",
    "else:\n",
    "    print(\"  MAPE    : Skipped (y_test contains zeros)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7703926-0ab0-47e7-acf3-a9ca7d65b9c8",
   "metadata": {},
   "source": [
    "# Final Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8431a9f-5f8c-4516-baa3-70dd558cae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final pipeline: Preprocessing + Model\n",
    "final_pipeline = Pipeline([\n",
    "    ('preprocessor', fitted_preprocessor),  # already fitted or will be fitted here\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5ef80fd-c840-49ba-a79e-e6ecd91491bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_pipeline.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(final_pipeline, \"random_forest_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b0db06d-b4c7-43e8-a7df-788018f7bb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_train.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(X_train, \"X_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1164883d-132c-4981-9139-af1444cd36e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(preprocessor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessor.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "joblib.dump(preprocessor, \"preprocessor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ad60ac0-1949-4304-a01c-1cb319c3608e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_train.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(y_train, \"y_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc2c218-98ae-4e2c-9a01-b28f47fede38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
